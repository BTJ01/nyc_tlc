{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure storage access info\n",
    "blob_account_name = \"azureopendatastorage\"\n",
    "blob_container_name = \"nyctlc\"\n",
    "blob_relative_path = \"yellow\"\n",
    "blob_sas_token = \"r\"\n",
    "\n",
    "# Allow SPARK to read from Blob remotely\n",
    "wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
    "spark.conf.set(\n",
    "  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
    "  blob_sas_token)\n",
    "print('Remote blob path: ' + wasbs_path)\n",
    "\n",
    "# SPARK read parquet, note that it won't load any data yet\n",
    "df = spark.read.parquet(wasbs_path)\n",
    "print('Register the DataFrame as a SQL temporary view: nyc_tlc')\n",
    "df.createOrReplaceTempView('nyc_tlc')\n",
    "\n",
    "# Enable cache to avoid repeated reads when querying full dataset\n",
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"true\")\n",
    "\n",
    "# Display top 10 rows\n",
    "print('Displaying top 10 rows: ')\n",
    "display(spark.sql('SELECT * FROM nyc_tlc LIMIT 10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display potential columns of interest, top 10 rows\n",
    "sql = '''\n",
    "SELECT \n",
    "    vendorID,\n",
    "    paymentType,\n",
    "    puYear,\n",
    "    puMonth,\n",
    "    passengerCount,\n",
    "    fareAmount,\n",
    "    improvementSurcharge,\n",
    "    extra,\n",
    "    mtaTax,\n",
    "    tollsAmount,\n",
    "    tipAmount,\n",
    "    totalAmount\n",
    "FROM nyc_tlc\n",
    "LIMIT 10;\n",
    "'''\n",
    "\n",
    "# Display the result of the SQL query\n",
    "display(spark.sql(sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and median costs, prices, and passenger counts\n",
    "# Aggregate by payment type, year, and month\n",
    "sql = '''\n",
    "SELECT\n",
    "    CASE UPPER(paymentType) \n",
    "        WHEN 'CREDIT' || 'CRE' || '1' THEN 'CRD'\n",
    "        WHEN 'CASH' || 'CAS' || '2' THEN 'CSH'\n",
    "        WHEN 'NO CHARGE' || 'NO' || '3' THEN 'NOC'\n",
    "        WHEN 'DISPUTE' || '4' THEN 'DIS'\n",
    "        WHEN 'VOIDED TRIP' || '6' THEN 'VOID'\n",
    "        ELSE 'UNKNOWN'\n",
    "      END AS paymentType,\n",
    "    puYear as Year,\n",
    "    puMonth as Month,\n",
    "    concat(string(puMonth),'/', string(puYear)) AS month_year,\n",
    "    AVG(passengerCount) AS avg_passenger_count,\n",
    "    MEDIAN(passengerCount) AS median_passenger_count,\n",
    "    AVG(fareAmount) AS avg_fareAmount,\n",
    "    MEDIAN(fareAmount) AS median_fareAmount,\n",
    "    AVG(improvementSurcharge) AS avg_improvementSurcharge,\n",
    "    MEDIAN(improvementSurcharge) median_improvementSurcharge,\n",
    "    AVG(extra) AS avg_extra,\n",
    "    MEDIAN(extra) AS median_extra,\n",
    "    AVG(mtaTax) AS avg_mtaTax,\n",
    "    MEDIAN(mtaTax) AS median_mtaTax,\n",
    "    AVG(tollsAmount) AS avg_tollsAmount,\n",
    "    MEDIAN(tollsAmount) AS median_tollsAmount,\n",
    "    AVG(tipAmount) AS avg_tipAmount,\n",
    "    MEDIAN(tipAmount) AS median_tipAmount,\n",
    "    AVG(totalAmount) AS avg_totalAmount,\n",
    "    MEDIAN(totalAmount) AS median_totalAmount\n",
    "FROM nyc_tlc\n",
    "WHERE puYear > 2008  -- few years of junk prior to 2009\n",
    "GROUP BY 1,2,3\n",
    "ORDER BY 3,2,1;\n",
    "'''\n",
    "\n",
    "# Display the result of the SQL query\n",
    "display(spark.sql(sql))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
