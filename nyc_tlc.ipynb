{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure storage access info\n",
    "blob_account_name = \"azureopendatastorage\"\n",
    "blob_container_name = \"nyctlc\"\n",
    "blob_relative_path = \"yellow\"\n",
    "blob_sas_token = \"r\"\n",
    "\n",
    "# Allow SPARK to read from Blob remotely\n",
    "wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
    "spark.conf.set(\n",
    "  'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
    "  blob_sas_token)\n",
    "print('Remote blob path: ' + wasbs_path)\n",
    "\n",
    "# SPARK read parquet, note that it won't load any data yet\n",
    "df = spark.read.parquet(wasbs_path)\n",
    "print('Register the DataFrame as a SQL temporary view: source')\n",
    "df.createOrReplaceTempView('source')\n",
    "\n",
    "# Enable cache to avoid repeated reads\n",
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"true\")\n",
    "\n",
    "# Display all columns, top 10 rows\n",
    "print('Displaying top 10 rows: ')\n",
    "display(spark.sql('SELECT * FROM source LIMIT 10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns of interest, top 10 rows\n",
    "sql = '''\n",
    "SELECT \n",
    "    vendorID,\n",
    "    passengerCount,\n",
    "    puMonth,\n",
    "    puYear,\n",
    "    paymentType,\n",
    "    fareAmount,\n",
    "    improvementSurcharge,\n",
    "    extra,\n",
    "    mtaTax,\n",
    "    tollsAmount,\n",
    "    tipAmount,\n",
    "    totalAmount\n",
    "FROM source\n",
    "LIMIT 10\n",
    "'''\n",
    "\n",
    "# Display the result of the SQL query\n",
    "display(spark.sql(sql))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
